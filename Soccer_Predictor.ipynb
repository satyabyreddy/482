{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/saife245/english-premier-league?resource=download&select=final_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_17100\\1459717881.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training Accuracy: 0.9799, Validation Accuracy: 0.6067\n",
      "Random Forest - Training Loss: 0.7246, Validation Loss: 14.1751\n",
      "\n",
      "XGBoost - Training Accuracy: 0.6811, Validation Accuracy: 0.6374\n",
      "XGBoost - Training Loss: 11.4942, Validation Loss: 13.0685\n",
      "\n",
      "Gradient Boosting - Training Accuracy: 0.6901, Validation Accuracy: 0.6374\n",
      "Gradient Boosting - Training Loss: 11.1714, Validation Loss: 13.0685\n",
      "\n",
      "Logistic Regression - Training Accuracy: 0.6462, Validation Accuracy: 0.6520\n",
      "Logistic Regression - Training Loss: 12.7523, Validation Loss: 12.5415\n",
      "\n",
      "Decision Tree - Training Accuracy: 0.9799, Validation Accuracy: 0.5570\n",
      "Decision Tree - Training Loss: 0.7246, Validation Loss: 15.9667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# Selecting and renaming columns\n",
    "data = data[['FTR','HTGD','ATGD','HTP','ATP','DiffFormPts','DiffPts','HM1', 'HM2','HM3','HM4','HM5','AM1','AM2','AM3','AM4','AM5']]\n",
    "data.columns = ['Result','HTGD','ATGD','HTP','ATP','DiffFormPts','DiffPts','H1', 'H2','H3','H4','H5','A1','A2','A3','A4','A5']\n",
    "\n",
    "# Preparing target variable\n",
    "y = pd.get_dummies(data[\"Result\"])['H']\n",
    "\n",
    "# Feature engineering\n",
    "X = data.drop(['Result'], axis=1)\n",
    "X = pd.get_dummies(X)  # Convert categorical variables into dummy/indicator variables\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initializing models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# Training and evaluating models\n",
    "for name, model in models.items():\n",
    "    # For XGBoost, performing a simple hyperparameter tuning\n",
    "    if name == 'XGBoost':\n",
    "        param_grid = {'n_estimators': [100], 'learning_rate': [0.1], 'max_depth': [3]}\n",
    "        model = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    \n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_val = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    loss_train = log_loss(y_train, y_pred_train)\n",
    "    loss_val = log_loss(y_val, y_pred_val)\n",
    "    \n",
    "    print(f\"{name} - Training Accuracy: {acc_train:.4f}, Validation Accuracy: {acc_val:.4f}\")\n",
    "    print(f\"{name} - Training Loss: {loss_train:.4f}, Validation Loss: {loss_val:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
